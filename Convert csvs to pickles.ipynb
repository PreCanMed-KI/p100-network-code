{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the provided csv files into pickle files\n",
    "\n",
    "It is possible that you will encounter a problem where you are running a different version of *pandas* that is not backwords/forwards compatible with *0.19.1*, which is what was used to generate the pickle files that are run in these notebooks.  \n",
    "\n",
    "If that happens you can regenerate the pickle files using the below code.\n",
    "\n",
    "We have included the code used to generate the csv and metadata files, so you can see how they were generated, in case you need to debug them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logging to convert-csvs-to-pickle.log\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    run_once\n",
    "except NameError:\n",
    "    run_once = False\n",
    "if not run_once:\n",
    "    run_once = True\n",
    "    \n",
    "    import time\n",
    "    import logging\n",
    "    reload(logging)\n",
    "    FORMAT = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "    logpath = 'convert-csvs-to-pickle.log'\n",
    "    logging.basicConfig(filename=logpath,level=logging.DEBUG, format=FORMAT)\n",
    "    print(\"logging to %s\" % (logpath))\n",
    "    logger = logging.getLogger()\n",
    "    #logger.basicConfig(filename='/notebooks/Export Microbiome to database.log',level=logging.DEBUG)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setLevel(logging.DEBUG)\n",
    "\n",
    "    # create formatter\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "    # add formatter to ch\n",
    "    ch.setFormatter(formatter)\n",
    "\n",
    "    # add ch to logger\n",
    "    logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import pandas, pandas.io\n",
    "print pandas.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the base of the data directory in the jupyter notebook\n",
    "DATA_DIR = '/home/jovyan/work/data'\n",
    "# the base of the csv directory in the jupyter notebook\n",
    "CSV_DIR = '/home/jovyan/work/data/csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create CSVs from pickles and store associated metadata\n",
    "\n",
    "Some things don't translate well between csvs and pandas objects, like is this a series or a dataframe, does the column index have a name, etc.\n",
    "\n",
    "So that info is stored in a json file.\n",
    "\n",
    "This creates the csvs and json metadata file in the `CSV_DIR`.\n",
    "\n",
    "You probably don't want to run this, but it is included so it is obvious how we created the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote /home/jovyan/work/data/csv/participant_data.csv\n",
      "Wrote /home/jovyan/work/data/csv/participant_data.json\n",
      "Wrote /home/jovyan/work/data/csv/6081.MICRO.phylum.annotations.csv\n",
      "Wrote /home/jovyan/work/data/csv/6081.MICRO.phylum.annotations.json\n",
      "Wrote /home/jovyan/work/data/csv/6082.MICRO.class.dataframe.csv\n",
      "Wrote /home/jovyan/work/data/csv/6082.MICRO.class.dataframe.json\n",
      "Wrote /home/jovyan/work/data/csv/6079.MICRO.diversity.dataframe.csv\n",
      "Wrote /home/jovyan/work/data/csv/6079.MICRO.diversity.dataframe.json\n",
      "Wrote /home/jovyan/work/data/csv/6081.MICRO.phylum.dataframe.csv\n",
      "Wrote /home/jovyan/work/data/csv/6081.MICRO.phylum.dataframe.json\n",
      "Wrote /home/jovyan/work/data/csv/6075.PROTE.None.dataframe.csv\n",
      "Wrote /home/jovyan/work/data/csv/6075.PROTE.None.dataframe.json\n",
      "Wrote /home/jovyan/work/data/csv/6084.MICRO.family.dataframe.csv\n",
      "Wrote /home/jovyan/work/data/csv/6084.MICRO.family.dataframe.json\n",
      "Wrote /home/jovyan/work/data/csv/6077.CHEMS.None.annotations.csv\n",
      "Wrote /home/jovyan/work/data/csv/6077.CHEMS.None.annotations.json\n",
      "Wrote /home/jovyan/work/data/csv/6083.MICRO.order.dataframe.csv\n",
      "Wrote /home/jovyan/work/data/csv/6083.MICRO.order.dataframe.json\n",
      "Wrote /home/jovyan/work/data/csv/ds_id_map.csv\n",
      "Wrote /home/jovyan/work/data/csv/ds_id_map.json\n",
      "Wrote /home/jovyan/work/data/csv/6077.CHEMS.None.dataframe.csv\n",
      "Wrote /home/jovyan/work/data/csv/6077.CHEMS.None.dataframe.json\n",
      "Wrote /home/jovyan/work/data/csv/6075.PROTE.None.annotations.csv\n",
      "Wrote /home/jovyan/work/data/csv/6075.PROTE.None.annotations.json\n",
      "Wrote /home/jovyan/work/data/csv/6078.COACH.coach.annotations.csv\n",
      "Wrote /home/jovyan/work/data/csv/6078.COACH.coach.annotations.json\n",
      "Wrote /home/jovyan/work/data/csv/6076.GENOM.trait.annotations.csv\n",
      "Wrote /home/jovyan/work/data/csv/6076.GENOM.trait.annotations.json\n",
      "Wrote /home/jovyan/work/data/csv/6074.METAB.None.annotations.csv\n",
      "Wrote /home/jovyan/work/data/csv/6074.METAB.None.annotations.json\n",
      "Wrote /home/jovyan/work/data/csv/6076.GENOM.trait.dataframe.csv\n",
      "Wrote /home/jovyan/work/data/csv/6076.GENOM.trait.dataframe.json\n",
      "Wrote /home/jovyan/work/data/csv/6078.COACH.coach.dataframe.csv\n",
      "Wrote /home/jovyan/work/data/csv/6078.COACH.coach.dataframe.json\n",
      "Wrote /home/jovyan/work/data/csv/6083.MICRO.order.annotations.csv\n",
      "Wrote /home/jovyan/work/data/csv/6083.MICRO.order.annotations.json\n",
      "Wrote /home/jovyan/work/data/csv/6074.METAB.None.dataframe.csv\n",
      "Wrote /home/jovyan/work/data/csv/6074.METAB.None.dataframe.json\n",
      "Wrote /home/jovyan/work/data/csv/6079.MICRO.diversity.annotations.csv\n",
      "Wrote /home/jovyan/work/data/csv/6079.MICRO.diversity.annotations.json\n",
      "Wrote /home/jovyan/work/data/csv/6084.MICRO.family.annotations.csv\n",
      "Wrote /home/jovyan/work/data/csv/6084.MICRO.family.annotations.json\n",
      "Wrote /home/jovyan/work/data/csv/6082.MICRO.class.annotations.csv\n",
      "Wrote /home/jovyan/work/data/csv/6082.MICRO.class.annotations.json\n",
      "Wrote /home/jovyan/work/data/csv/community/correlation_network.DELTA.sig.nodups.INTRAOMIC.csv\n",
      "Wrote /home/jovyan/work/data/csv/community/correlation_network.DELTA.sig.nodups.INTRAOMIC.json\n",
      "Wrote /home/jovyan/work/data/csv/community/correlation_network.nodups.INTRAOMIC.csv\n",
      "Wrote /home/jovyan/work/data/csv/community/correlation_network.nodups.INTRAOMIC.json\n",
      "Wrote /home/jovyan/work/data/csv/community/full.DELTA.correlation.network.csv\n",
      "Wrote /home/jovyan/work/data/csv/community/full.DELTA.correlation.network.json\n",
      "Wrote /home/jovyan/work/data/csv/community/full.correlation.network.csv\n",
      "Wrote /home/jovyan/work/data/csv/community/full.correlation.network.json\n",
      "Wrote /home/jovyan/work/data/csv/community/correlation_network.DELTA.sig.nodups.FULL.csv\n",
      "Wrote /home/jovyan/work/data/csv/community/correlation_network.DELTA.sig.nodups.FULL.json\n",
      "Wrote /home/jovyan/work/data/csv/community/correlation_network.sig.nodups.FULL.csv\n",
      "Wrote /home/jovyan/work/data/csv/community/correlation_network.sig.nodups.FULL.json\n"
     ]
    }
   ],
   "source": [
    "raise Exception(\"You probably don't want to run this\")\n",
    "\n",
    "def create_csv_and_json(sub, pickle_file):\n",
    "    df = pandas.read_pickle(os.path.join(DATA_DIR, sub, pickle_file))\n",
    "    # create a dict to capture important metadata\n",
    "    meta = {'index_name':df.index.name}\n",
    "    \n",
    "    if isinstance(df, pandas.Series):\n",
    "        meta['type'] = \"Series\"\n",
    "        meta['dtype'] = str(df.dtypes)\n",
    "    elif isinstance(df, pandas.DataFrame):\n",
    "        meta['type'] = \"DataFrame\"\n",
    "        meta['columns_name'] = df.columns.name\n",
    "        meta['dtypes'] = {k:str(v) for k,v in df.dtypes.to_dict().items()}\n",
    "        meta['index_dtype'] = str(df.index.dtype)\n",
    "        meta['columns_dtype'] = str(df.columns.dtype)\n",
    "    else:\n",
    "        raise Exception(\"WTF\")\n",
    "    csv_name = pickle_file[:-3] + 'csv'\n",
    "    json_name = pickle_file[:-3] + 'json'\n",
    "    csv_path = os.path.join(CSV_DIR, sub, csv_name)\n",
    "    json_path = os.path.join(CSV_DIR, sub, json_name)\n",
    "    \n",
    "    if isinstance(df.index, pandas.MultiIndex):\n",
    "        raise Exception(\"WTF\")\n",
    "    df.to_csv(csv_path)\n",
    "    print \"Wrote\", csv_path\n",
    "    with open(json_path, 'w') as js:\n",
    "        json.dump(meta, js)\n",
    "    print \"Wrote\", json_path\n",
    "        \n",
    "\n",
    "        \n",
    "# traverse root directory, and list directories as dirs and files as files\n",
    "for root, dirs, files in os.walk(DATA_DIR):\n",
    "    path = root.split(os.sep)\n",
    "    sub = root[len(DATA_DIR):]\n",
    "    #print((len(path) - 1) * '---', os.path.basename(root))\n",
    "    if sub.find('csv') == -1:\n",
    "        for fil in files:\n",
    "            if fil[-3:] == 'pkl':\n",
    "\n",
    "                #print(len(path) * '---', fil)\n",
    "                #print sub\n",
    "                create_csv_and_json(sub.lstrip(os.sep), fil)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This creates pickle files from the metadata and the csv files\n",
    "\n",
    "The pickle files are stored in the csv directory.  You will want to move them to the data and data/community directories as is appropriate.\n",
    "\n",
    "Note, the original pickles have the data from the database at the original precision.  Some precision gets lost in the conversion to decimal in the csv files.\n",
    "\n",
    "This should not matter much, but it may affect results slightly, i.e. a 1.3 x 10^-3 as opposed to a 1.2999997 x 10^-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_pickle(sub, csv_file):\n",
    "    json_file = csv_file[:-3] + 'json'\n",
    "    print csv_file\n",
    "    meta = json.load(open(os.path.join(CSV_DIR, sub, json_file), 'r'))\n",
    "    # print meta\n",
    "    if meta['type'] == 'Series':\n",
    "        series = pandas.read_csv(os.path.join(CSV_DIR, sub, csv_file), \n",
    "                        float_precision='high',\n",
    "                        index_col = 0,\n",
    "                        header=None\n",
    "                       )\n",
    "        if meta['index_name'] is not None:\n",
    "            series.index.name = meta['index_name']\n",
    "        series = series[series.columns[0]]\n",
    "        series = series.astype(meta['dtype'])\n",
    "        series.to_pickle(os.path.join(CSV_DIR, sub, csv_file[:-3] + 'pkl'))\n",
    "        print \"Wrote\", os.path.join(CSV_DIR, sub, csv_file[:-3] + 'pkl')\n",
    "        #print series.head()\n",
    "    else:\n",
    "        dataframe = pandas.read_csv(os.path.join(CSV_DIR, sub, csv_file), \n",
    "                        float_precision='high',\n",
    "                        index_col = 0\n",
    "                       )\n",
    "        if meta['index_name'] is not None:\n",
    "            dataframe.index.name = meta['index_name']\n",
    "        if meta['columns_name'] is not None:\n",
    "            dataframe.columns.name = meta['columns_name']\n",
    "            \n",
    "        dataframe.columns = dataframe.columns.astype(meta['columns_dtype'])\n",
    "\n",
    "        dataframe = dataframe.astype({k:v for k,v in meta['dtypes'].items() if k in dataframe.columns})\n",
    "        dataframe.index = dataframe.index.astype(meta['index_dtype'])\n",
    "        if 'username' in dataframe.columns:\n",
    "            dataframe = dataframe.astype({'username':str})\n",
    "        dataframe.to_pickle(os.path.join(CSV_DIR, sub, csv_file[:-3] + 'pkl'))\n",
    "        print \"Wrote\", os.path.join(CSV_DIR, sub, csv_file[:-3] + 'pkl')\n",
    "        #print dataframe.head()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('---------------', 'csv')\n",
      "6081.MICRO.phylum.annotations.csv\n",
      "Wrote /home/jovyan/work/data/csv/6081.MICRO.phylum.annotations.pkl\n",
      "6082.MICRO.class.dataframe.csv\n",
      "Wrote /home/jovyan/work/data/csv/6082.MICRO.class.dataframe.pkl\n",
      "6074.METAB.None.dataframe.csv\n",
      "Wrote /home/jovyan/work/data/csv/6074.METAB.None.dataframe.pkl\n",
      "6075.PROTE.None.dataframe.csv\n",
      "Wrote /home/jovyan/work/data/csv/6075.PROTE.None.dataframe.pkl\n",
      "6075.PROTE.None.annotations.csv\n",
      "Wrote /home/jovyan/work/data/csv/6075.PROTE.None.annotations.pkl\n",
      "6078.COACH.coach.dataframe.csv\n",
      "Wrote /home/jovyan/work/data/csv/6078.COACH.coach.dataframe.pkl\n",
      "6079.MICRO.diversity.annotations.csv\n",
      "Wrote /home/jovyan/work/data/csv/6079.MICRO.diversity.annotations.pkl\n",
      "participant_data.csv\n",
      "Wrote /home/jovyan/work/data/csv/participant_data.pkl\n",
      "6082.MICRO.class.annotations.csv\n",
      "Wrote /home/jovyan/work/data/csv/6082.MICRO.class.annotations.pkl\n",
      "6084.MICRO.family.annotations.csv\n",
      "Wrote /home/jovyan/work/data/csv/6084.MICRO.family.annotations.pkl\n",
      "6084.MICRO.family.dataframe.csv\n",
      "Wrote /home/jovyan/work/data/csv/6084.MICRO.family.dataframe.pkl\n",
      "ds_id_map.csv\n",
      "Wrote /home/jovyan/work/data/csv/ds_id_map.pkl\n",
      "6074.METAB.None.annotations.csv\n",
      "Wrote /home/jovyan/work/data/csv/6074.METAB.None.annotations.pkl\n",
      "6076.GENOM.trait.annotations.csv\n",
      "Wrote /home/jovyan/work/data/csv/6076.GENOM.trait.annotations.pkl\n",
      "6078.COACH.coach.annotations.csv\n",
      "Wrote /home/jovyan/work/data/csv/6078.COACH.coach.annotations.pkl\n",
      "6083.MICRO.order.dataframe.csv\n",
      "Wrote /home/jovyan/work/data/csv/6083.MICRO.order.dataframe.pkl\n",
      "6076.GENOM.trait.dataframe.csv\n",
      "Wrote /home/jovyan/work/data/csv/6076.GENOM.trait.dataframe.pkl\n",
      "6077.CHEMS.None.dataframe.csv\n",
      "Wrote /home/jovyan/work/data/csv/6077.CHEMS.None.dataframe.pkl\n",
      "6079.MICRO.diversity.dataframe.csv\n",
      "Wrote /home/jovyan/work/data/csv/6079.MICRO.diversity.dataframe.pkl\n",
      "6077.CHEMS.None.annotations.csv\n",
      "Wrote /home/jovyan/work/data/csv/6077.CHEMS.None.annotations.pkl\n",
      "6083.MICRO.order.annotations.csv\n",
      "Wrote /home/jovyan/work/data/csv/6083.MICRO.order.annotations.pkl\n",
      "6081.MICRO.phylum.dataframe.csv\n",
      "Wrote /home/jovyan/work/data/csv/6081.MICRO.phylum.dataframe.pkl\n",
      "('------------------', 'community')\n",
      "full.DELTA.correlation.network.csv\n",
      "Wrote /home/jovyan/work/data/csv/community/full.DELTA.correlation.network.pkl\n",
      "full.correlation.network.csv\n",
      "Wrote /home/jovyan/work/data/csv/community/full.correlation.network.pkl\n",
      "correlation_network.DELTA.sig.nodups.FULL.csv\n",
      "Wrote /home/jovyan/work/data/csv/community/correlation_network.DELTA.sig.nodups.FULL.pkl\n",
      "correlation_network.sig.nodups.FULL.csv\n",
      "Wrote /home/jovyan/work/data/csv/community/correlation_network.sig.nodups.FULL.pkl\n",
      "correlation_network.DELTA.sig.nodups.INTRAOMIC.csv\n",
      "Wrote /home/jovyan/work/data/csv/community/correlation_network.DELTA.sig.nodups.INTRAOMIC.pkl\n",
      "correlation_network.nodups.INTRAOMIC.csv\n",
      "Wrote /home/jovyan/work/data/csv/community/correlation_network.nodups.INTRAOMIC.pkl\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(CSV_DIR):\n",
    "    path = root.split(os.sep)\n",
    "    sub = root[len(CSV_DIR):]\n",
    "    print((len(path) - 1) * '---', os.path.basename(root))\n",
    "    for fil in files:\n",
    "        if fil[-3:] == 'csv':\n",
    "            create_pickle(sub.lstrip(os.sep), fil)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test that the conversions are in range\n",
    "\n",
    "Note this requires you have the original pickles, so it is probably not relevant.\n",
    "\n",
    "If you need this, it means there has been a breaking change in pandas, so that pickle no longer works on the original files.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/data/participant_data.pkl == /home/jovyan/work/data/csv/participant_data.pkl\n",
      "/home/jovyan/work/data/6081.MICRO.phylum.annotations.pkl == /home/jovyan/work/data/csv/6081.MICRO.phylum.annotations.pkl\n",
      "/home/jovyan/work/data/6082.MICRO.class.dataframe.pkl != /home/jovyan/work/data/csv/6082.MICRO.class.dataframe.pkl\n",
      "Datatypes match\n",
      "Columns match\n",
      "Indices match\n",
      "Numerics are Close enough\n",
      "/home/jovyan/work/data/6079.MICRO.diversity.dataframe.pkl != /home/jovyan/work/data/csv/6079.MICRO.diversity.dataframe.pkl\n",
      "Datatypes match\n",
      "Columns match\n",
      "Indices match\n",
      "Numerics are Close enough\n",
      "/home/jovyan/work/data/6081.MICRO.phylum.dataframe.pkl != /home/jovyan/work/data/csv/6081.MICRO.phylum.dataframe.pkl\n",
      "Datatypes match\n",
      "Columns match\n",
      "Indices match\n",
      "Numerics are Close enough\n",
      "/home/jovyan/work/data/6075.PROTE.None.dataframe.pkl != /home/jovyan/work/data/csv/6075.PROTE.None.dataframe.pkl\n",
      "Datatypes match\n",
      "Columns match\n",
      "Indices match\n",
      "Numerics are Close enough\n",
      "/home/jovyan/work/data/6084.MICRO.family.dataframe.pkl != /home/jovyan/work/data/csv/6084.MICRO.family.dataframe.pkl\n",
      "Datatypes match\n",
      "Columns match\n",
      "Indices match\n",
      "Numerics are Close enough\n",
      "/home/jovyan/work/data/6077.CHEMS.None.annotations.pkl == /home/jovyan/work/data/csv/6077.CHEMS.None.annotations.pkl\n",
      "/home/jovyan/work/data/6083.MICRO.order.dataframe.pkl != /home/jovyan/work/data/csv/6083.MICRO.order.dataframe.pkl\n",
      "Datatypes match\n",
      "Columns match\n",
      "Indices match\n",
      "Numerics are Close enough\n",
      "/home/jovyan/work/data/ds_id_map.pkl == /home/jovyan/work/data/csv/ds_id_map.pkl\n",
      "/home/jovyan/work/data/6077.CHEMS.None.dataframe.pkl != /home/jovyan/work/data/csv/6077.CHEMS.None.dataframe.pkl\n",
      "Datatypes match\n",
      "Columns match\n",
      "Indices match\n",
      "Numerics are Close enough\n",
      "/home/jovyan/work/data/6075.PROTE.None.annotations.pkl == /home/jovyan/work/data/csv/6075.PROTE.None.annotations.pkl\n",
      "/home/jovyan/work/data/6078.COACH.coach.annotations.pkl == /home/jovyan/work/data/csv/6078.COACH.coach.annotations.pkl\n",
      "/home/jovyan/work/data/6076.GENOM.trait.annotations.pkl == /home/jovyan/work/data/csv/6076.GENOM.trait.annotations.pkl\n",
      "/home/jovyan/work/data/6074.METAB.None.annotations.pkl == /home/jovyan/work/data/csv/6074.METAB.None.annotations.pkl\n",
      "/home/jovyan/work/data/6076.GENOM.trait.dataframe.pkl != /home/jovyan/work/data/csv/6076.GENOM.trait.dataframe.pkl\n",
      "Datatypes match\n",
      "Columns match\n",
      "Indices match\n",
      "Numerics are Close enough\n",
      "/home/jovyan/work/data/6078.COACH.coach.dataframe.pkl != /home/jovyan/work/data/csv/6078.COACH.coach.dataframe.pkl\n",
      "Datatypes match\n",
      "Columns match\n",
      "Indices match\n",
      "Numerics are Close enough\n",
      "/home/jovyan/work/data/6083.MICRO.order.annotations.pkl == /home/jovyan/work/data/csv/6083.MICRO.order.annotations.pkl\n",
      "/home/jovyan/work/data/6074.METAB.None.dataframe.pkl != /home/jovyan/work/data/csv/6074.METAB.None.dataframe.pkl\n",
      "Datatypes match\n",
      "Columns match\n",
      "Indices match\n",
      "Numerics are Close enough\n",
      "/home/jovyan/work/data/6079.MICRO.diversity.annotations.pkl == /home/jovyan/work/data/csv/6079.MICRO.diversity.annotations.pkl\n",
      "/home/jovyan/work/data/6084.MICRO.family.annotations.pkl == /home/jovyan/work/data/csv/6084.MICRO.family.annotations.pkl\n",
      "/home/jovyan/work/data/6082.MICRO.class.annotations.pkl == /home/jovyan/work/data/csv/6082.MICRO.class.annotations.pkl\n",
      "/home/jovyan/work/data/community/correlation_network.DELTA.sig.nodups.INTRAOMIC.pkl != /home/jovyan/work/data/csv/community/correlation_network.DELTA.sig.nodups.INTRAOMIC.pkl\n",
      "Datatypes match\n",
      "Columns match\n",
      "Indices match\n",
      "Nonnumerics match\n",
      "Numerics are Close enough\n",
      "/home/jovyan/work/data/community/correlation_network.nodups.INTRAOMIC.pkl != /home/jovyan/work/data/csv/community/correlation_network.nodups.INTRAOMIC.pkl\n",
      "Datatypes match\n",
      "Columns match\n",
      "Indices match\n",
      "Nonnumerics match\n",
      "Numerics are Close enough\n",
      "/home/jovyan/work/data/community/full.DELTA.correlation.network.pkl != /home/jovyan/work/data/csv/community/full.DELTA.correlation.network.pkl\n",
      "Datatypes match\n",
      "Columns match\n",
      "Indices match\n",
      "Nonnumerics match\n",
      "Numerics are Close enough\n",
      "/home/jovyan/work/data/community/full.correlation.network.pkl != /home/jovyan/work/data/csv/community/full.correlation.network.pkl\n",
      "Datatypes match\n",
      "Columns match\n",
      "Indices match\n",
      "Nonnumerics match\n",
      "Numerics are Close enough\n",
      "/home/jovyan/work/data/community/correlation_network.DELTA.sig.nodups.FULL.pkl != /home/jovyan/work/data/csv/community/correlation_network.DELTA.sig.nodups.FULL.pkl\n",
      "Datatypes match\n",
      "Columns match\n",
      "Indices match\n",
      "Nonnumerics match\n",
      "Numerics are Close enough\n",
      "/home/jovyan/work/data/community/correlation_network.sig.nodups.FULL.pkl != /home/jovyan/work/data/csv/community/correlation_network.sig.nodups.FULL.pkl\n",
      "Datatypes match\n",
      "Columns match\n",
      "Indices match\n",
      "Nonnumerics match\n",
      "Numerics are Close enough\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "raise Exception(\"Are you sure? If so delete me\")\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(DATA_DIR):\n",
    "    path = root.split(os.sep)\n",
    "    sub = root[len(DATA_DIR):]\n",
    "    #print((len(path) - 1) * '---', os.path.basename(root))\n",
    "    if sub.find('csv') == -1:\n",
    "        for fil in files:\n",
    "            if fil[-3:] == 'pkl':\n",
    "                orig_df = pandas.read_pickle(os.path.join(root,fil))\n",
    "                copied_df = pandas.read_pickle(os.path.join(CSV_DIR, sub.lstrip('/'), fil))\n",
    "                if orig_df.equals(copied_df):\n",
    "                    print os.path.join(root,fil), \"==\", os.path.join(CSV_DIR, sub.lstrip('/'), fil)\n",
    "                else:\n",
    "                    show_stopper = False\n",
    "                    print os.path.join(root,fil), \"!=\", os.path.join(CSV_DIR, sub.lstrip('/'), fil)\n",
    "                    if np.all(orig_df.dtypes == copied_df.dtypes):\n",
    "                        print \"Datatypes match\"\n",
    "                    else:\n",
    "                        show_stopper = True\n",
    "                    ocl = orig_df.columns.tolist()\n",
    "                    ccl = copied_df.columns.tolist()\n",
    "                    if len(ocl) == len(ccl) and ((set(ocl) & set(ccl)) == set(ccl)):\n",
    "                        print \"Columns match\"\n",
    "                    else:\n",
    "                        show_stopper = True\n",
    "                    ocl = orig_df.index.tolist()\n",
    "                    ccl = copied_df.index.tolist()\n",
    "                    if len(ocl) == len(ccl) and ((set(ocl) & set(ccl)) == set(ccl)):\n",
    "                        print \"Indices match\"\n",
    "                    else:\n",
    "                        show_stopper = True\n",
    "                    \n",
    "                    nd = orig_df._get_numeric_data().columns.tolist()\n",
    "                    nnd = [c for c in orig_df.columns if c not in nd]\n",
    "                    if len(nnd) > 0:\n",
    "                        if not np.all(orig_df[nnd] == copied_df[nnd]):\n",
    "                            show_stopper = True\n",
    "                            print \"Nonumerics do not match\"\n",
    "                        else:\n",
    "                            print \"Nonnumerics match\"\n",
    "                    \n",
    "                    if (copied_df._get_numeric_data() - orig_df._get_numeric_data()).abs().sum().sum() < .00001:\n",
    "                        print \"Numerics are Close enough\"\n",
    "                    else:\n",
    "                        show_stopper = True\n",
    "                    if show_stopper:\n",
    "                        raise Exception(\"Out of range dataframes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
